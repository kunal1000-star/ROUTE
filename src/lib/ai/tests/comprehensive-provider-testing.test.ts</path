// Comprehensive AI Provider Testing Suite
// ========================================

import { describe, test, expect, beforeAll, afterAll, beforeEach, afterEach } from 'vitest';
import { aiServiceManager } from '../ai-service-manager';
import { rateLimitTracker } from '../rate-limit-tracker';
import { responseCache } from '../response-cache';
import { semanticSearch } from '../semantic-search';
import type { AIServiceManagerRequest, AIServiceManagerResponse } from '@/types/ai-service-manager';

// Provider configurations for testing
const PROVIDER_CONFIGS = {
  groq: {
    name: 'groq',
    models: ['llama-3.3-70b-versatile', 'llama-3.1-70b-versatile', 'mixtral-8x7b-32768'],
    capabilities: {
      streaming: true,
      function_calling: true,
      json_mode: true
    }
  },
  cohere: {
    name: 'cohere',
    models: ['command', 'command-light', 'command-r', 'command-r-plus'],
    capabilities: {
      streaming: true,
      function_calling: false,
      json_mode: true
    }
  },
  mistral: {
    name: 'mistral',
    models: ['mistral-tiny', 'mistral-small', 'mistral-medium', 'mistral-large'],
    capabilities: {
      streaming: true,
      function_calling: true,
      json_mode: false
    }
  },
  gemini: {
    name: 'gemini',
    models: ['gemini-1.5-flash', 'gemini-1.5-pro'],
    capabilities: {
      streaming: true,
      function_calling: true,
      json_mode: true
    }
  },
  openrouter: {
    name: 'openrouter',
    models: ['anthropic/claude-3.5-sonnet', 'openai/gpt-4-turbo'],
    capabilities: {
      streaming: true,
      function_calling: true,
      json_mode: true
    }
  },
  cerebras: {
    name: 'cerebras',
    models: ['llama3.1-70b', 'llama3.1-8b'],
    capabilities: {
      streaming: true,
      function_calling: false,
      json_mode: false
    }
  }
};

interface TestResult {
  provider: string;
  success: boolean;
  responseTime: number;
  tokensUsed: number;
  error?: string;
  modelUsed: string;
}

describe('Comprehensive AI Provider Testing Suite', () => {
  const testUserId = 'comprehensive-test-user';
  const testConversationId = 'comprehensive-test-conv';
  const testMessages = [
    'Explain quantum computing in simple terms',
    'What are the key differences between machine learning and deep learning?',
    'How does blockchain technology work?',
    'What are the applications of artificial intelligence in healthcare?',
    'Explain the concept of entropy in physics'
  ];

  beforeAll(() => {
    // Clean up caches before testing
    responseCache.clear();
    rateLimitTracker.cleanup();
  });

  afterAll(() => {
    // Clean up after testing
    responseCache.clear();
  });

  describe('Provider Availability and Health', () => {
    test('should check health of all configured providers', async () => {
      const healthResults: Record<string, any> = {};
      
      for (const [providerName, config] of Object.entries(PROVIDER_CONFIGS)) {
        try {
          const startTime = Date.now();
          
          // Test basic chat functionality with health check message
          const request: AIServiceManagerRequest = {
            userId: `${testUserId}-health-${providerName}`,
            message: 'Health check - respond with "OK"',
            conversationId: `${testConversationId}-health-${providerName}`,
            chatType: 'general',
            includeAppData: false,
            providerPreference: providerName as any
          };
          
          const response = await aiServiceManager.processQuery(request);
          const endTime = Date.now();
          
          healthResults[providerName] = {
            healthy: true,
            responseTime: endTime - startTime,
            modelUsed: response.model_used,
            tokensUsed: response.tokens_used.input + response.tokens_used.output,
            success: true
          };
          
        } catch (error) {
          healthResults[providerName] = {
            healthy: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            success: false
          };
        }
      }
      
      // Log health results
      console.log('Provider Health Check Results:', healthResults);
      
      // At least some providers should be healthy
      const healthyProviders = Object.entries(healthResults)
        .filter(([, result]) => result.healthy)
        .length;
      
      expect(healthyProviders).toBeGreaterThan(0);
      
      // Store results for subsequent tests
      (global as any).healthResults = healthResults;
    }, 30000);
  });

  describe('Model Capability Testing', () => {
    test('should test each provider with multiple models', async () => {
      const modelTestResults: Record<string, TestResult[]> = {};
      
      for (const [providerName, config] of Object.entries(PROVIDER_CONFIGS)) {
        const results: TestResult[] = [];
        
        for (const model of config.models.slice(0, 2)) { // Test first 2 models per provider
          try {
            const testMessage = `Test message for ${providerName} with model ${model}`;
            
            const request: AIServiceManagerRequest = {
              userId: `${testUserId}-model-${providerName}-${model}`,
              message: testMessage,
              conversationId: `${testConversationId}-model-${providerName}-${model}`,
              chatType: 'general',
              includeAppData: false,
              providerPreference: providerName as any
            };
            
            const startTime = Date.now();
            const response = await aiServiceManager.processQuery(request);
            const endTime = Date.now();
            
            results.push({
              provider: providerName,
              success: true,
              responseTime: endTime - startTime,
              tokensUsed: response.tokens_used.input + response.tokens_used.output,
              modelUsed: response.model_used,
            });
            
          } catch (error) {
            results.push({
              provider: providerName,
              success: false,
              responseTime: 0,
              tokensUsed: 0,
              modelUsed: model,
              error: error instanceof Error ? error.message : 'Unknown error'
            });
          }
        }
        
        modelTestResults[providerName] = results;
      }
      
      console.log('Model Test Results:', modelTestResults);
      
      // Verify that at least one model per provider works
      for (const [providerName, results] of Object.entries(modelTestResults)) {
        const successfulTests = results.filter(r => r.success).length;
        expect(successfulTests).toBeGreaterThan(0);
      }
      
      (global as any).modelTestResults = modelTestResults;
    }, 60000);
  });

  describe('Response Quality Testing', () => {
    test('should evaluate response quality across providers', async () => {
      const qualityTestResults: Record<string, any> = {};
      
      for (const [providerName, config] of Object.entries(PROVIDER_CONFIGS)) {
        const responses: any[] = [];
        
        // Test with a complex question that requires reasoning
        const complexQuestion = 'Explain the relationship between quantum mechanics and general relativity, and discuss why they are difficult to unify.';
        
        for (let i = 0; i < 3; i++) {
          try {
            const request: AIServiceManagerRequest = {
              userId: `${testUserId}-quality-${providerName}-${i}`,
              message: complexQuestion,
              conversationId: `${testConversationId}-quality-${providerName}-${i}`,
              chatType: 'study_assistant',
              includeAppData: false,
              providerPreference: providerName as any
            };
            
            const startTime = Date.now();
            const response = await aiServiceManager.processQuery(request);
            const endTime = Date.now();
            
            // Evaluate response quality
            const qualityScore = evaluateResponseQuality(response.content);
            
            responses.push({
              content: response.content,
              responseTime: endTime - startTime,
              tokensUsed: response.tokens_used.input + response.tokens_used.output,
              qualityScore,
              wordCount: response.content.split(' ').length,
              modelUsed: response.model_used
            });
            
          } catch (error) {
            responses.push({
              error: error instanceof Error ? error.message : 'Unknown error',
              success: false
            });
          }
        }
        
        qualityTestResults[providerName] = responses;
      }
      
      console.log('Quality Test Results:', qualityTestResults);
      
      // Store results for analysis
      (global as any).qualityTestResults = qualityTestResults;
    }, 90000);
  });

  describe('Performance Benchmarking', () => {
    test('should benchmark response times across providers', async () => {
      const benchmarkResults: Record<string, any> = {};
      
      for (const [providerName, config] of Object.entries(PROVIDER_CONFIGS)) {
        const responseTimes: number[] = [];
        const tokenCounts: number[] = [];
        let successCount = 0;
        
        // Test with 5 different messages
        for (const message of testMessages) {
          try {
            const request: AIServiceManagerRequest = {
              userId: `${testUserId}-benchmark-${providerName}-${Math.random()}`,
              message: message,
              conversationId: `${testConversationId}-benchmark-${providerName}`,
              chatType: 'general',
              includeAppData: false,
              providerPreference: providerName as any
            };
            
            const startTime = Date.now();
            const response = await aiServiceManager.processQuery(request);
            const endTime = Date.now();
            
            responseTimes.push(endTime - startTime);
            tokenCounts.push(response.tokens_used.input + response.tokens_used.output);
            successCount++;
            
            // Small delay between requests
            await new Promise(resolve => setTimeout(resolve, 100));
            
          } catch (error) {
            // Log error but continue with other requests
            console.warn(`Benchmark failed for ${providerName}:`, error);
          }
        }
        
        benchmarkResults[providerName] = {
          averageResponseTime: responseTimes.length > 0 ? 
            responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length : 0,
          minResponseTime: responseTimes.length > 0 ? Math.min(...responseTimes) : 0,
          maxResponseTime: responseTimes.length > 0 ? Math.max(...responseTimes) : 0,
          averageTokens: tokenCounts.length > 0 ?
            tokenCounts.reduce((a, b) => a + b, 0) / tokenCounts.length : 0,
          successRate: successCount / testMessages.length,
          totalRequests: testMessages.length,
          successfulRequests: successCount
        };
      }
      
      console.log('Performance Benchmark Results:', benchmarkResults);
      
      // Store results for reporting
      (global as any).benchmarkResults = benchmarkResults;
    }, 120000);
  });

  describe('Error Handling and Resilience', () => {
    test('should test provider resilience under various conditions', async () => {
      const resilienceResults: Record<string, any> = {};
      
      for (const [providerName, config] of Object.entries(PROVIDER_CONFIGS)) {
        const tests = {
          emptyMessage: false,
          veryLongMessage: false,
          specialCharacters: false,
          rapidRequests: false
        };
        
        // Test empty message
        try {
          const request: AIServiceManagerRequest = {
            userId: `${testUserId}-resilience-${providerName}`,
            message: '',
            conversationId: `${testConversationId}-resilience-${providerName}`,
            chatType: 'general',
            includeAppData: false,
            providerPreference: providerName as any
          };
          
          await aiServiceManager.processQuery(request);
          tests.emptyMessage = true;
        } catch (error) {
          // Empty message should be handled gracefully
          tests.emptyMessage = error instanceof Error && 
            (error.message.includes('empty') || error.message.includes('invalid'));
        }
        
        // Test very long message
        try {
          const longMessage = 'Explain quantum computing. '.repeat(1000);
          const request: AIServiceManagerRequest = {
            userId: `${testUserId}-resilience-long-${providerName}`,
            message: longMessage,
            conversationId: `${testConversationId}-resilience-long-${providerName}`,
            chatType: 'general',
            includeAppData: false,
            providerPreference: providerName as any
          };
          
          const response = await aiServiceManager.processQuery(request);
          tests.veryLongMessage = response.content.length > 0;
        } catch (error) {
          // Long message might be rejected or truncated
          tests.veryLongMessage = true; // Consider it handled if it doesn't crash
        }
        
        // Test special characters
        try {
          const specialMessage = 'Test with Ã©mojis ðŸš€ and spÃ«ciÃ¥l chÃ¥rsâ„¢ and symbols: âˆ€âˆƒâˆˆâˆ‰';
          const request: AIServiceManagerRequest = {
            userId: `${testUserId}-resilience-special-${providerName}`,
            message: specialMessage,
            conversationId: `${testConversationId}-resilience-special-${providerName}`,
            chatType: 'general',
            includeAppData: false,
            providerPreference: providerName as any
          };
          
          const response = await aiServiceManager.processQuery(request);
          tests.specialCharacters = response.content.length > 0;
        } catch (error) {
          tests.specialCharacters = false;
        }
        
        // Test rapid requests (rate limiting)
        try {
          const rapidPromises = [];
          for (let i = 0; i < 5; i++) {
            const request: AIServiceManagerRequest = {
              userId: `${testUserId}-resilience-rapid-${providerName}-${i}`,
              message: 'Rapid test message',
              conversationId: `${testConversationId}-resilience-rapid-${providerName}-${i}`,
              chatType: 'general',
              includeAppData: false,
              providerPreference: providerName as any
            };
            
            rapidPromises.push(aiServiceManager.processQuery(request));
          }
          
          const rapidResults = await Promise.allSettled(rapidPromises);
          tests.rapidRequests = rapidResults.filter(r => r.status === 'fulfilled').length > 0;
        } catch (error) {
          tests.rapidRequests = false;
        }
        
        resilienceResults[providerName] = tests;
      }
      
      console.log('Resilience Test Results:', resilienceResults);
      
      // Store results for analysis
      (global as any).resilienceResults = resilienceResults;
    }, 60000);
  });

  describe('Integration with AI Service Manager', () => {
    test('should verify proper integration with AI service manager', async () => {
      // Test fallback mechanism
      const fallbackTest: any = {};
      
      // Test with invalid provider preference
      try {
        const request: AIServiceManagerRequest = {
          userId: `${testUserId}-fallback-test`,
          message: 'Test fallback mechanism',
          conversationId: `${testConversationId}-fallback-test`,
          chatType: 'general',
          includeAppData: false,
          providerPreference: 'invalid-provider' as any // Should trigger fallback
        };
        
        const startTime = Date.now();
        const response = await aiServiceManager.processQuery(request);
        const endTime = Date.now();
        
        fallbackTest.result = {
          success: true,
          fallbackUsed: response.fallback_used,
          responseTime: endTime - startTime,
          provider: response.provider,
          modelUsed: response.model_used
        };
        
      } catch (error) {
        fallbackTest.result = {
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error'
        };
      }
      
      // Test without provider preference (automatic selection)
      try {
        const request: AIServiceManagerRequest = {
          userId: `${testUserId}-auto-selection-test`,
          message: 'Test automatic provider selection',
          conversationId: `${testConversationId}-auto-selection-test`,
          chatType: 'general',
          includeAppData: false
          // No providerPreference - should use automatic selection
        };
        
        const startTime = Date.now();
        const response = await aiServiceManager.processQuery(request);
        const endTime = Date.now();
        
        fallbackTest.autoSelection = {
          success: true,
          responseTime: endTime - startTime,
          provider: response.provider,
          modelUsed: response.model_used
        };
        
      } catch (error) {
        fallbackTest.autoSelection = {
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error'
        };
      }
      
      console.log('Integration Test Results:', fallbackTest);
      
      // Store results
      (global as any).integrationTestResults = fallbackTest;
    }, 30000);
  });

  describe('Provider Comparison Report', () => {
    test('should generate comprehensive provider comparison report', async () => {
      // Generate comparison report using stored test results
      const healthResults = (global as any).healthResults || {};
      const modelTestResults = (global as any).modelTestResults || {};
      const benchmarkResults = (global as any).benchmarkResults || {};
      const resilienceResults = (global as any).resilienceResults || {};
      
      const comparisonReport: Record<string, any> = {};
      
      for (const providerName of Object.keys(PROVIDER_CONFIGS)) {
        const health = healthResults[providerName] || {};
        const models = modelTestResults[providerName] || [];
        const benchmarks = benchmarkResults[providerName] || {};
        const resilience = resilienceResults[providerName] || {};
        
        comparisonReport[providerName] = {
          health: {
            available: health.healthy || false,
            averageResponseTime: health.responseTime || 0,
            reliability: health.success ? 'high' : 'low'
          },
          performance: {
            averageResponseTime: benchmarks.averageResponseTime || 0,
            successRate: benchmarks.successRate || 0,
            tokensPerSecond: benchmarks.averageTokens > 0 && benchmarks.averageResponseTime > 0 ?
              (benchmarks.averageTokens / benchmarks.averageResponseTime) * 1000 : 0
          },
          models: {
            totalModels: PROVIDER_CONFIGS[providerName as keyof typeof PROVIDER_CONFIGS].models.length,
            workingModels: models.filter((m: any) => m.success).length,
            averageTokensPerModel: models.length > 0 ?
              models.reduce((sum: number, m: any) => sum + m.tokensUsed, 0) / models.length : 0
          },
          resilience: {
            emptyMessageHandling: resilience.emptyMessage || false,
            longMessageHandling: resilience.veryLongMessage || false,
            specialCharacterHandling: resilience.specialCharacters || false,
            rateLimitHandling: resilience.rapidRequests || false
          },
          recommendation: generateProviderRecommendation(health, benchmarks, models, resilience)
        };
      }
      
      console.log('=== COMPREHENSIVE PROVIDER COMPARISON REPORT ===');
      console.log(JSON.stringify(comparisonReport, null, 2));
      console.log('=== END REPORT ===');
      
      // Verify that we have results for all providers
      expect(Object.keys(comparisonReport)).toHaveLength(Object.keys(PROVIDER_CONFIGS).length);
      
      // Store final report
      (global as any).finalComparisonReport = comparisonReport;
    });
  });
});

// Utility functions
function evaluateResponseQuality(content: string): number {
  let score = 0;
  
  // Basic length check
  if (content.length > 100) score += 20;
  if (content.length > 300) score += 20;
  if (content.length > 500) score += 20;
  
  // Check for structured content
  if (content.includes('\n')) score += 10; // Line breaks suggest structure
  if (content.match(/\d+\./)) score += 10; // Numbered lists
  if (content.match(/[A-Z][a-z]+:/)) score += 10; // Capitalized headings
  
  // Check for technical terms
  const technicalTerms = ['algorithm', 'function', 'system', 'process', 'method', 'approach', 'solution'];
  const termCount = technicalTerms.filter(term => 
    content.toLowerCase().includes(term.toLowerCase())
  ).length;
  score += Math.min(termCount * 5, 20); // Max 20 points for technical content
  
  return Math.min(score, 100);
}

function generateProviderRecommendation(health: any, benchmarks: any, models: any[], resilience: any): string {
  const score = {
    availability: health.healthy ? 25 : 0,
    performance: benchmarks.successRate > 0.8 ? 25 : benchmarks.successRate > 0.5 ? 15 : 5,
    reliability: models.filter(m => m.success).length > 0 ? 25 : 0,
    resilience: Object.values(resilience).filter(Boolean).length > 2 ? 25 : 10
  };
  
  const totalScore = Object.values(score).reduce((a, b) => a + b, 0);
  
  if (totalScore >= 80) return 'Highly Recommended';
  if (totalScore >= 60) return 'Recommended';
  if (totalScore >= 40) return 'Acceptable';
  return 'Not Recommended';
}
